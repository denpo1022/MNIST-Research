{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "e8bbfa4db6a428b863a8d4105049b28908e39f4302d7212165242677d21cc14e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Assignment 1: Experiment with handwritten text recognition using different optimization methods provided in Keras."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tensorflow-gpu 2.3.1\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters setup\n",
    "\n",
    "EPOCHS = 50 # The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset.\n",
    "\n",
    "BATCH_SIZE = 128 # The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters.\n",
    "\n",
    "VERBOSE = 1 # Used for decide how much output we want when training the model.\n",
    "\n",
    "NB_CLASSES = 10 # Number of outputs = number of digits (from 0 ~ 9)\n",
    "\n",
    "N_HIDDEN = 128 # Positive integer, dimensionality of the output space.\n",
    "\n",
    "VALIDATION_SPLIT = 0.2 # How much TRAIN is reserved for VALIDATION.\n",
    "\n",
    "DROPOUT = 0.3 # The ratio of dropout variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60000 train samples\n10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Loading MNIST dataset, verifing the split between train and test is 60,000, and 10,000 respectly.\n",
    "# One-hot is automatically applied.\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Applying normalization in [0,1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# one-hot\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_layer (Dense)          (None, 128)               100480    \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\ndense_layer_2 (Dense)        (None, 128)               16512     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_layer_3 (Dense)        (None, 10)                1290      \n=================================================================\nTotal params: 118,282\nTrainable params: 118,282\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "source": [
    "## Using optimizer SGD (stochastic gradient decent)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "299 - val_loss: 0.1616 - val_accuracy: 0.9534\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9307 - val_loss: 0.1589 - val_accuracy: 0.9548\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9320 - val_loss: 0.1564 - val_accuracy: 0.9554\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9320 - val_loss: 0.1552 - val_accuracy: 0.9552\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9330 - val_loss: 0.1529 - val_accuracy: 0.9553\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.9346 - val_loss: 0.1500 - val_accuracy: 0.9564\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9360 - val_loss: 0.1478 - val_accuracy: 0.9565\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9381 - val_loss: 0.1467 - val_accuracy: 0.9578\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9381 - val_loss: 0.1440 - val_accuracy: 0.9571\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9392 - val_loss: 0.1422 - val_accuracy: 0.9588\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9399 - val_loss: 0.1400 - val_accuracy: 0.9592\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9414 - val_loss: 0.1381 - val_accuracy: 0.9598\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9408 - val_loss: 0.1376 - val_accuracy: 0.9598\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.9412 - val_loss: 0.1359 - val_accuracy: 0.9592\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.9422 - val_loss: 0.1348 - val_accuracy: 0.9603\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.9427 - val_loss: 0.1323 - val_accuracy: 0.9612\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9432 - val_loss: 0.1322 - val_accuracy: 0.9611\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9440 - val_loss: 0.1302 - val_accuracy: 0.9615\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9448 - val_loss: 0.1292 - val_accuracy: 0.9614\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9446 - val_loss: 0.1278 - val_accuracy: 0.9625\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9451 - val_loss: 0.1264 - val_accuracy: 0.9630\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9462 - val_loss: 0.1256 - val_accuracy: 0.9629\n",
      "313/313 [==============================] - 0s 461us/step - loss: 0.1238 - accuracy: 0.9628\n",
      "Test accuracy: 0.9628000259399414\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer_2 (Dense)        (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer_3 (Dense)        (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.6776 - accuracy: 0.4734 - val_loss: 0.8808 - val_accuracy: 0.8176\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.9079 - accuracy: 0.7208 - val_loss: 0.5196 - val_accuracy: 0.8723\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.7893 - val_loss: 0.4124 - val_accuracy: 0.8907\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.8206 - val_loss: 0.3631 - val_accuracy: 0.8988\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.8435 - val_loss: 0.3302 - val_accuracy: 0.9079\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.8551 - val_loss: 0.3074 - val_accuracy: 0.9124\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.8636 - val_loss: 0.2911 - val_accuracy: 0.9162\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8731 - val_loss: 0.2758 - val_accuracy: 0.9204\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.4067 - accuracy: 0.8789 - val_loss: 0.2646 - val_accuracy: 0.9227\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8833 - val_loss: 0.2540 - val_accuracy: 0.9252\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8882 - val_loss: 0.2440 - val_accuracy: 0.9276\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8930 - val_loss: 0.2359 - val_accuracy: 0.9310\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8971 - val_loss: 0.2305 - val_accuracy: 0.9318\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8999 - val_loss: 0.2222 - val_accuracy: 0.9345\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.9046 - val_loss: 0.2158 - val_accuracy: 0.9368\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.9050 - val_loss: 0.2104 - val_accuracy: 0.9393\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.9075 - val_loss: 0.2046 - val_accuracy: 0.9409\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.9105 - val_loss: 0.2005 - val_accuracy: 0.9429\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.9128 - val_loss: 0.1947 - val_accuracy: 0.9438\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.9149 - val_loss: 0.1916 - val_accuracy: 0.9451\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.9159 - val_loss: 0.1872 - val_accuracy: 0.9468\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2783 - accuracy: 0.9181 - val_loss: 0.1840 - val_accuracy: 0.9473\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.9194 - val_loss: 0.1806 - val_accuracy: 0.9487\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.9216 - val_loss: 0.1759 - val_accuracy: 0.9501\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2612 - accuracy: 0.9236 - val_loss: 0.1740 - val_accuracy: 0.9503\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.9238 - val_loss: 0.1701 - val_accuracy: 0.9511\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.9254 - val_loss: 0.1676 - val_accuracy: 0.9520\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.9270 - val_loss: 0.1646 - val_accuracy: 0.9528\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9284 - val_loss: 0.1619 - val_accuracy: 0.9542\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.9295 - val_loss: 0.1605 - val_accuracy: 0.9540\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.9311 - val_loss: 0.1574 - val_accuracy: 0.9550\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9315 - val_loss: 0.1546 - val_accuracy: 0.9557\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2294 - accuracy: 0.9316 - val_loss: 0.1530 - val_accuracy: 0.9561\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9333 - val_loss: 0.1503 - val_accuracy: 0.9566\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9343 - val_loss: 0.1482 - val_accuracy: 0.9572\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9362 - val_loss: 0.1466 - val_accuracy: 0.9573\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9379 - val_loss: 0.1455 - val_accuracy: 0.9578\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.9392 - val_loss: 0.1427 - val_accuracy: 0.9581\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.9401 - val_loss: 0.1414 - val_accuracy: 0.9581\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.9390 - val_loss: 0.1395 - val_accuracy: 0.9597\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9393 - val_loss: 0.1379 - val_accuracy: 0.9596\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9410 - val_loss: 0.1366 - val_accuracy: 0.9606\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9413 - val_loss: 0.1344 - val_accuracy: 0.9609\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9411 - val_loss: 0.1331 - val_accuracy: 0.9604\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9419 - val_loss: 0.1320 - val_accuracy: 0.9616\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.9436 - val_loss: 0.1310 - val_accuracy: 0.9621\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9447 - val_loss: 0.1295 - val_accuracy: 0.9618\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9441 - val_loss: 0.1281 - val_accuracy: 0.9622\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9442 - val_loss: 0.1267 - val_accuracy: 0.9627\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9458 - val_loss: 0.1259 - val_accuracy: 0.9635\n",
      "  1/313 [..............................] - ETA: 0s - loss: 0.0877 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "313/313 [==============================] - 0s 482us/step - loss: 0.1255 - accuracy: 0.9607\n",
      "Test accuracy: 0.9606999754905701\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer_2 (Dense)        (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer_3 (Dense)        (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.6874 - accuracy: 0.4520 - val_loss: 0.8878 - val_accuracy: 0.8127\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.9112 - accuracy: 0.7167 - val_loss: 0.5340 - val_accuracy: 0.8670\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.7862 - val_loss: 0.4264 - val_accuracy: 0.8899\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.8184 - val_loss: 0.3745 - val_accuracy: 0.8997\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.8415 - val_loss: 0.3404 - val_accuracy: 0.9075\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.8546 - val_loss: 0.3169 - val_accuracy: 0.9120\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8656 - val_loss: 0.3010 - val_accuracy: 0.9147\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8718 - val_loss: 0.2867 - val_accuracy: 0.9186\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8778 - val_loss: 0.2723 - val_accuracy: 0.9221\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8840 - val_loss: 0.2612 - val_accuracy: 0.9258\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8884 - val_loss: 0.2526 - val_accuracy: 0.9286\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8917 - val_loss: 0.2433 - val_accuracy: 0.9291\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8954 - val_loss: 0.2349 - val_accuracy: 0.9319\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8996 - val_loss: 0.2284 - val_accuracy: 0.9339\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.9026 - val_loss: 0.2218 - val_accuracy: 0.9365\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.9062 - val_loss: 0.2157 - val_accuracy: 0.9381\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.9079 - val_loss: 0.2099 - val_accuracy: 0.9398\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.9099 - val_loss: 0.2048 - val_accuracy: 0.9403\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.9131 - val_loss: 0.1994 - val_accuracy: 0.9420\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.9155 - val_loss: 0.1958 - val_accuracy: 0.9433\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2818 - accuracy: 0.9171 - val_loss: 0.1913 - val_accuracy: 0.9440\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.9183 - val_loss: 0.1875 - val_accuracy: 0.9449\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.9200 - val_loss: 0.1830 - val_accuracy: 0.9463\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.9211 - val_loss: 0.1793 - val_accuracy: 0.9477\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2600 - accuracy: 0.9235 - val_loss: 0.1774 - val_accuracy: 0.9491\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2573 - accuracy: 0.9240 - val_loss: 0.1737 - val_accuracy: 0.9492\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2528 - accuracy: 0.9266 - val_loss: 0.1695 - val_accuracy: 0.9519\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.9276 - val_loss: 0.1676 - val_accuracy: 0.9507\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.9287 - val_loss: 0.1654 - val_accuracy: 0.9517\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9291 - val_loss: 0.1623 - val_accuracy: 0.9532\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9308 - val_loss: 0.1599 - val_accuracy: 0.9536\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.9317 - val_loss: 0.1574 - val_accuracy: 0.9544\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9318 - val_loss: 0.1552 - val_accuracy: 0.9552\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9348 - val_loss: 0.1533 - val_accuracy: 0.9549\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9331 - val_loss: 0.1514 - val_accuracy: 0.9557\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9358 - val_loss: 0.1493 - val_accuracy: 0.9566\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.9367 - val_loss: 0.1478 - val_accuracy: 0.9576\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9371 - val_loss: 0.1464 - val_accuracy: 0.9570\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.9379 - val_loss: 0.1442 - val_accuracy: 0.9582\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9391 - val_loss: 0.1422 - val_accuracy: 0.9585\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9393 - val_loss: 0.1410 - val_accuracy: 0.9585\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.9415 - val_loss: 0.1390 - val_accuracy: 0.9595\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9410 - val_loss: 0.1377 - val_accuracy: 0.9596\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9422 - val_loss: 0.1358 - val_accuracy: 0.9603\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.9404 - val_loss: 0.1345 - val_accuracy: 0.9608\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.9431 - val_loss: 0.1341 - val_accuracy: 0.9609\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9444 - val_loss: 0.1326 - val_accuracy: 0.9610\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9435 - val_loss: 0.1317 - val_accuracy: 0.9613\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9447 - val_loss: 0.1298 - val_accuracy: 0.9623\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9453 - val_loss: 0.1288 - val_accuracy: 0.9627\n",
      "313/313 [==============================] - 0s 459us/step - loss: 0.1257 - accuracy: 0.9624\n",
      "Test accuracy: 0.9624000191688538\n"
     ]
    }
   ],
   "source": [
    "test_acc_results = []\n",
    "\n",
    "# Train and evaluate the model 10 times and get the average test accuracy for comparison\n",
    "for i in range(10):\n",
    "\t# Build the model\n",
    "\n",
    "\t# Sequential provides training and inference features on this model.\n",
    "\tmodel = tf.keras.models.Sequential()\n",
    "\n",
    "\tmodel.add(keras.layers.Dense(N_HIDDEN,\n",
    "\t\t\tinput_shape=(RESHAPED,),\n",
    "\t\t\tname='dense_layer', activation='relu'))\n",
    "\tmodel.add(keras.layers.Dropout(DROPOUT))\n",
    "\tmodel.add(keras.layers.Dense(N_HIDDEN,\n",
    "\t\t\tname='dense_layer_2', activation='relu'))\n",
    "\tmodel.add(keras.layers.Dropout(DROPOUT))\n",
    "\tmodel.add(keras.layers.Dense(NB_CLASSES,\n",
    "\t\t\tname='dense_layer_3', activation='softmax'))\n",
    "\n",
    "\t# Summary of the model\n",
    "\tmodel.summary()\n",
    "\n",
    "\t# Compile the model\n",
    "\tmodel.compile(optimizer='SGD', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\t# Train the moodel\n",
    "\tmodel.fit(X_train, Y_train,\n",
    "\t\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "\t\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "\t# Evalute the model\n",
    "\ttest_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "\tprint('Test accuracy:', test_acc)\n",
    "\ttest_acc_results.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average test accuracy using SGD is : 0.9620800137519836\n"
     ]
    }
   ],
   "source": [
    "print(\"Average test accuracy using SGD is :\", sum(test_acc_results) / len(test_acc_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}